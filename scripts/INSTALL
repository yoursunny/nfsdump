# $Id: INSTALL,v 1.3 2007/04/17 21:11:28 ellard Exp $
#
# Copyright (c) 2002-2003 by the President and Fellows of Harvard
# College.  All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that:  (1) source code
# distributions retain the above copyright notice and this paragraph
# in its entirety, (2) distributions including binary code include
# the above copyright notice and this paragraph in its entirety in
# the documentation or other materials provided with the
# distribution, and (3) all advertising materials mentioning features
# or use of this software display the following acknowledgement: 
# ``This product includes software developed by the Harvard
# University, and its contributors.'' Neither the name of the
# University nor the names of its contributors may be used to endorse
# or promote products derived from this software without specific
# prior written permission.
#
# THIS SOFTWARE IS PROVIDED ``AS IS'' AND WITHOUT ANY EXPRESS OR
# IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.
#
# Daniel Ellard
#
# Bugs/Comments/Suggestions to Daniel Ellard (ellard@eecs.harvard.edu).

For the purpose of these instructions, DIR is the name of the directory
where the nfsdump distribution was installed.

Notes:

    - If you have PERL installed somewhere other than /usr/bin, you
	will need to edit all the PERL scripts to use the correct
	path.

1.  cd into DIR/scripts.

2.  Choose a name for your collection.  This string is used as
	part of the filenames of the data files, so it should be
	something that identifies the system being traced.

	As an example, I'll call this FOO.

2.  Copy host.tmplt to FOO.tmplt

3.  Edit FOO.tmplt.  Follow the directions in the file.

	For most situations, all you will need to do is define LogName
	(which should be FOO) and RootDir (which should be DIR).

4.  Test FOO.tmplt and configure the data directories by running
	nfs-setup.pl:

	./nfs-setup.pl FOO.tmplt

	If successful, nfs-setup.sh will create and initialize the
	data directories according to the parameters in FOO.tmplt.  If
	there are any errors, edit FOO.tmplt as needed.

4.  Create a cron job to run the zipper at regular intervals.  This is
	a process that compresses the log files, reducing their size
	by at least a factor of 10.  Add the following to root's
	crontab:

	5 * * * * * DIR/scripts/nfs-zipper.pl DIR/scripts/FOO.tmplt

	(replacing DIR with the appropriate directory, of course)

5.  You can either run the nfs-logger from the command line, or else
	you can run it via a cron job as well.  If you run it via
	cron, make sure you edit the tmplt file accordingly -- the
	data can be scrambled if you have two loggers running at the
	same time, and if there are periods when there isn't a logger
	running at all, the data will have holes.

	If you change the LifeTime parameter in the tmplt file to one
	day (24 * 60) you can have the logger start running every
	morning at 3am via the following cron job:

		0 3 * * * DIR/scripts/nfs-logger.pl DIR/scripts/FOO.tmplt

	or you can run it directly from the command line:

		DIR/scripts/nfs-logger.pl DIR/scripts/FOO.tmplt

